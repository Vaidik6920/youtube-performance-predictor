{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b8842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2531741\ttest: 0.2587594\tbest: 0.2587594 (0)\ttotal: 3.69s\tremaining: 30m 41s\n",
      "50:\tlearn: 0.4586093\ttest: 0.4587602\tbest: 0.4598703 (49)\ttotal: 3m 27s\tremaining: 30m 30s\n",
      "100:\tlearn: 0.5097587\ttest: 0.5047481\tbest: 0.5047481 (100)\ttotal: 7m 2s\tremaining: 27m 49s\n",
      "150:\tlearn: 0.5516949\ttest: 0.5381790\tbest: 0.5381790 (150)\ttotal: 10m 43s\tremaining: 24m 47s\n",
      "200:\tlearn: 0.5823063\ttest: 0.5539518\tbest: 0.5539518 (200)\ttotal: 14m 13s\tremaining: 21m 9s\n",
      "250:\tlearn: 0.6057994\ttest: 0.5683452\tbest: 0.5689522 (245)\ttotal: 17m 32s\tremaining: 17m 23s\n",
      "300:\tlearn: 0.6293990\ttest: 0.5775385\tbest: 0.5775385 (300)\ttotal: 20m 49s\tremaining: 13m 46s\n",
      "350:\tlearn: 0.6408540\ttest: 0.5817196\tbest: 0.5834477 (349)\ttotal: 24m 8s\tremaining: 10m 14s\n",
      "400:\tlearn: 0.6504682\ttest: 0.5888616\tbest: 0.5915244 (391)\ttotal: 27m 37s\tremaining: 6m 49s\n",
      "450:\tlearn: 0.6618873\ttest: 0.5944585\tbest: 0.5951202 (441)\ttotal: 31m 38s\tremaining: 3m 26s\n",
      "499:\tlearn: 0.6742555\ttest: 0.5952554\tbest: 0.5952554 (499)\ttotal: 35m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5952553748\n",
      "bestIteration = 499\n",
      "\n",
      "=== SECTOR MODEL METRICS (text + numeric only) ===\n",
      "Accuracy : 0.5966666666666667\n",
      "Macro F1 : 0.5952553747726216\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Education       0.56      0.48      0.52       400\n",
      "       Entertainment       0.54      0.62      0.58       400\n",
      "           Lifestyle       0.62      0.61      0.61       400\n",
      "     News & Politics       0.58      0.59      0.59       400\n",
      "Science & Technology       0.59      0.73      0.65       400\n",
      "              Sports       0.71      0.55      0.62       400\n",
      "\n",
      "            accuracy                           0.60      2400\n",
      "           macro avg       0.60      0.60      0.60      2400\n",
      "        weighted avg       0.60      0.60      0.60      2400\n",
      "\n",
      "\n",
      "Per‑sector accuracy:\n",
      "            sector_true  accuracy  support\n",
      "0             Education    0.4800      400\n",
      "1         Entertainment    0.6225      400\n",
      "2             Lifestyle    0.6100      400\n",
      "3       News & Politics    0.5925      400\n",
      "4  Science & Technology    0.7300      400\n",
      "5                Sports    0.5450      400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sector_cat_encoders.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_sector_model.py  (no channel, no fine/parent/youtube_categories)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import joblib\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(\"YouTube_Engineered_Features_Final.csv\")\n",
    "\n",
    "# target: sector\n",
    "df = df.dropna(subset=[\"sector\"]).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TEXT FEATURES\n",
    "# ------------------------------------------------------------\n",
    "TEXT_COLS = [\"youtube_title\", \"youtube_description\"]\n",
    "for c in TEXT_COLS:\n",
    "    df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# NO CATEGORICAL FEATURES (we exclude youtube_channel, fine/parent/etc.)\n",
    "# ------------------------------------------------------------\n",
    "CAT_COLS: list[str] = []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# NUMERIC FEATURES (safe, non-leaky)\n",
    "# ------------------------------------------------------------\n",
    "NUM_COLS = [\n",
    "    \"title_length_chars\",\n",
    "    \"title_word_count\",\n",
    "    \"description_length_chars\",\n",
    "    \"description_word_count\",\n",
    "    \"title_sentiment\",\n",
    "    \"title_subjectivity\",\n",
    "    \"description_sentiment\",\n",
    "    \"description_subjectivity\",\n",
    "    \"meta_description_sentiment\",\n",
    "    \"duration_seconds\",\n",
    "    \"youtube_channel_follower_count\",\n",
    "    \"audience_engagement_index\",\n",
    "    \"video_completeness_score\",\n",
    "    \"tts_quality_indicator\",\n",
    "    \"production_polish_score\",\n",
    "    \"views_per_subscriber\",\n",
    "    \"likes_per_subscriber\",\n",
    "    \"comments_per_subscriber\",\n",
    "    \"engagement_rate\",\n",
    "    \"like_rate\",\n",
    "    \"comment_rate\",\n",
    "    \"like_to_comment_ratio\",\n",
    "]\n",
    "\n",
    "NUM_COLS = [c for c in NUM_COLS if c in df.columns]\n",
    "df[NUM_COLS] = df[NUM_COLS].fillna(0.0).astype(float)\n",
    "\n",
    "# ============================================================\n",
    "# 2. BUILD TRAINING FRAME\n",
    "# ============================================================\n",
    "\n",
    "def build_sector_training_frame(df: pd.DataFrame):\n",
    "    # encode target\n",
    "    le_sector = LabelEncoder()\n",
    "    y = le_sector.fit_transform(df[\"sector\"].astype(str))\n",
    "\n",
    "    encoders = {}  # kept for API symmetry; empty because no CAT_COLS\n",
    "\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # add text\n",
    "    for c in TEXT_COLS:\n",
    "        X[c] = df[c]\n",
    "\n",
    "    # add numeric\n",
    "    for c in NUM_COLS:\n",
    "        X[c] = df[c]\n",
    "\n",
    "    feature_cols = list(X.columns)\n",
    "\n",
    "    text_idx = [feature_cols.index(c) for c in TEXT_COLS]\n",
    "    cat_idx: list[int] = []  # no categorical features\n",
    "\n",
    "    return X, y, feature_cols, text_idx, cat_idx, le_sector, encoders\n",
    "\n",
    "\n",
    "X_sector, y_sector, feature_cols_sector, text_idx, cat_idx, le_sector, cat_encoders = \\\n",
    "    build_sector_training_frame(df)\n",
    "\n",
    "# ============================================================\n",
    "# 3. TRAIN / VALIDATION SPLIT\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_sector,\n",
    "    y_sector,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_sector,\n",
    ")\n",
    "\n",
    "train_pool = Pool(X_train, y_train, text_features=text_idx)\n",
    "val_pool = Pool(X_val, y_val, text_features=text_idx)\n",
    "\n",
    "# ============================================================\n",
    "# 4. TRAIN CATBOOST (SECTOR PREDICTION)\n",
    "# ============================================================\n",
    "\n",
    "sector_model = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1:average=Macro\",\n",
    "    iterations=500,\n",
    "    learning_rate=0.08,\n",
    "    depth=6,\n",
    "    auto_class_weights=\"Balanced\",\n",
    "    random_seed=42,\n",
    "    text_processing={\n",
    "        \"feature_processing\": {\n",
    "            \"default\": [\n",
    "                \"BoW:top_tokens_count=8000\",\n",
    "                \"NaiveBayes\",\n",
    "                \"BM25\",\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    verbose=50,\n",
    ")\n",
    "\n",
    "sector_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ACCURACY CHECKS\n",
    "# ============================================================\n",
    "\n",
    "y_val_pred = sector_model.predict(val_pool).astype(int).ravel()\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "\n",
    "print(\"=== SECTOR MODEL METRICS (text + numeric only) ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Macro F1 :\", macro_f1)\n",
    "print(classification_report(y_val, y_val_pred, target_names=le_sector.classes_))\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    \"sector_true\": le_sector.inverse_transform(y_val),\n",
    "    \"sector_pred\": le_sector.inverse_transform(y_val_pred),\n",
    "})\n",
    "val_df[\"correct\"] = (val_df[\"sector_true\"] == val_df[\"sector_pred\"]).astype(int)\n",
    "sector_perf = (\n",
    "    val_df.groupby(\"sector_true\")[\"correct\"]\n",
    "    .agg([\"mean\", \"count\"])\n",
    "    .rename(columns={\"mean\": \"accuracy\", \"count\": \"support\"})\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"\\nPer‑sector accuracy:\")\n",
    "print(sector_perf)\n",
    "\n",
    "sector_perf.to_csv(\"sector_validation_metrics.csv\", index=False)\n",
    "\n",
    "# ============================================================\n",
    "# 6. SAVE ARTIFACTS\n",
    "# ============================================================\n",
    "\n",
    "sector_model.save_model(\"sector_model.cbm\")\n",
    "joblib.dump(le_sector, \"label_encoder_sector.pkl\")\n",
    "joblib.dump(feature_cols_sector, \"sector_feature_cols.joblib\")\n",
    "joblib.dump(text_idx, \"sector_text_idx.joblib\")\n",
    "joblib.dump(cat_idx, \"sector_cat_idx.joblib\")          # empty list\n",
    "joblib.dump(cat_encoders, \"sector_cat_encoders.joblib\")  # empty dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed254889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4461354\ttest: 0.4449311\tbest: 0.4449311 (0)\ttotal: 2.16s\tremaining: 17m 59s\n",
      "50:\tlearn: 0.9333860\ttest: 0.9287363\tbest: 0.9287363 (50)\ttotal: 2m 17s\tremaining: 20m 10s\n",
      "100:\tlearn: 0.9800791\ttest: 0.9791826\tbest: 0.9791826 (100)\ttotal: 4m 33s\tremaining: 18m 2s\n",
      "150:\tlearn: 0.9898985\ttest: 0.9879350\tbest: 0.9879350 (150)\ttotal: 9m 6s\tremaining: 21m 4s\n",
      "200:\tlearn: 0.9934448\ttest: 0.9921015\tbest: 0.9921015 (191)\ttotal: 13m 14s\tremaining: 19m 41s\n",
      "250:\tlearn: 0.9937583\ttest: 0.9925219\tbest: 0.9925219 (216)\ttotal: 17m 8s\tremaining: 16m 59s\n",
      "300:\tlearn: 0.9946939\ttest: 0.9937644\tbest: 0.9937644 (296)\ttotal: 21m 10s\tremaining: 13m 59s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9937644052\n",
      "bestIteration = 296\n",
      "\n",
      "Shrink model to first 297 iterations.\n",
      "=== SECTOR MODEL METRICS (text + extra text + numeric) ===\n",
      "Accuracy : 0.99375\n",
      "Macro F1 : 0.9937644052241983\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Education       1.00      0.99      0.99       400\n",
      "       Entertainment       0.99      0.99      0.99       400\n",
      "           Lifestyle       0.98      0.99      0.99       400\n",
      "     News & Politics       1.00      0.99      1.00       400\n",
      "Science & Technology       1.00      1.00      1.00       400\n",
      "              Sports       1.00      0.99      1.00       400\n",
      "\n",
      "            accuracy                           0.99      2400\n",
      "           macro avg       0.99      0.99      0.99      2400\n",
      "        weighted avg       0.99      0.99      0.99      2400\n",
      "\n",
      "\n",
      "Per‑sector accuracy:\n",
      "            sector_true  accuracy  support\n",
      "0             Education    0.9900      400\n",
      "1         Entertainment    0.9950      400\n",
      "2             Lifestyle    0.9925      400\n",
      "3       News & Politics    0.9925      400\n",
      "4  Science & Technology    0.9975      400\n",
      "5                Sports    0.9950      400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sector_cat_encoders.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_sector_model_with_extra_text.py\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import joblib\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(\"YouTube_Engineered_Features_Final.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"sector\"]).reset_index(drop=True)\n",
    "\n",
    "# ---------- helper to stringify list-like columns ----------\n",
    "def stringify_list_col(x):\n",
    "    if isinstance(x, list):\n",
    "        return \" \".join(str(t).strip() for t in x if str(t).strip())\n",
    "    try:\n",
    "        v = ast.literal_eval(str(x))\n",
    "        if isinstance(v, list):\n",
    "            return \" \".join(str(t).strip() for t in v if str(t).strip())\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = str(x).strip()\n",
    "    return s if s else \"\"\n",
    "\n",
    "# ============================================================\n",
    "# 2. BUILD TEXT FEATURE WITH EXTRA SIGNAL\n",
    "# ============================================================\n",
    "\n",
    "# base text\n",
    "df[\"youtube_title\"] = df[\"youtube_title\"].fillna(\"\").astype(str)\n",
    "df[\"youtube_description\"] = df[\"youtube_description\"].fillna(\"\").astype(str)\n",
    "\n",
    "# convert categories to plain text\n",
    "df[\"fine_cat_text\"] = df[\"content_fine_category\"].fillna(\"\").astype(str)\n",
    "df[\"yt_cat_text\"] = df[\"youtube_categories\"].apply(stringify_list_col)\n",
    "\n",
    "# combined text feature the model will use\n",
    "df[\"all_text\"] = (\n",
    "    df[\"youtube_title\"] + \" \" +\n",
    "    df[\"youtube_description\"] + \" \" +\n",
    "    df[\"fine_cat_text\"] + \" \" +\n",
    "    df[\"yt_cat_text\"]\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. NUMERIC FEATURES (safe, non-leaky)\n",
    "# ============================================================\n",
    "\n",
    "NUM_COLS = [\n",
    "    \"title_length_chars\",\n",
    "    \"title_word_count\",\n",
    "    \"description_length_chars\",\n",
    "    \"description_word_count\",\n",
    "    \"title_sentiment\",\n",
    "    \"title_subjectivity\",\n",
    "    \"description_sentiment\",\n",
    "    \"description_subjectivity\",\n",
    "    \"meta_description_sentiment\",\n",
    "    \"duration_seconds\",\n",
    "    \"youtube_channel_follower_count\",\n",
    "    \"audience_engagement_index\",\n",
    "    \"video_completeness_score\",\n",
    "    \"tts_quality_indicator\",\n",
    "    \"production_polish_score\",\n",
    "    \"views_per_subscriber\",\n",
    "    \"likes_per_subscriber\",\n",
    "    \"comments_per_subscriber\",\n",
    "    \"engagement_rate\",\n",
    "    \"like_rate\",\n",
    "    \"comment_rate\",\n",
    "    \"like_to_comment_ratio\",\n",
    "]\n",
    "\n",
    "NUM_COLS = [c for c in NUM_COLS if c in df.columns]\n",
    "df[NUM_COLS] = df[NUM_COLS].fillna(0.0).astype(float)\n",
    "\n",
    "# ============================================================\n",
    "# 4. BUILD TRAINING FRAME\n",
    "# ============================================================\n",
    "\n",
    "def build_sector_training_frame(df: pd.DataFrame):\n",
    "    # encode target\n",
    "    le_sector = LabelEncoder()\n",
    "    y = le_sector.fit_transform(df[\"sector\"].astype(str))\n",
    "\n",
    "    # feature frame: one text column + numeric columns\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "    X[\"all_text\"] = df[\"all_text\"]\n",
    "\n",
    "    for c in NUM_COLS:\n",
    "        X[c] = df[c]\n",
    "\n",
    "    feature_cols = list(X.columns)\n",
    "\n",
    "    # 'all_text' is the only text feature, at index 0\n",
    "    text_idx = [feature_cols.index(\"all_text\")]\n",
    "    cat_idx: list[int] = []  # no explicit categorical features\n",
    "\n",
    "    encoders = {}  # kept for consistency\n",
    "\n",
    "    return X, y, feature_cols, text_idx, cat_idx, le_sector, encoders\n",
    "\n",
    "\n",
    "X_sector, y_sector, feature_cols_sector, text_idx, cat_idx, le_sector, cat_encoders = \\\n",
    "    build_sector_training_frame(df)\n",
    "\n",
    "# ============================================================\n",
    "# 5. TRAIN / VALIDATION SPLIT\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_sector,\n",
    "    y_sector,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_sector,\n",
    ")\n",
    "\n",
    "train_pool = Pool(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    text_features=text_idx,   # only all_text is text\n",
    ")\n",
    "val_pool = Pool(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    text_features=text_idx,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6. TRAIN CATBOOST SECTOR MODEL\n",
    "# ============================================================\n",
    "\n",
    "sector_model = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1:average=Macro\",\n",
    "    iterations=500,\n",
    "    learning_rate=0.08,\n",
    "    depth=6,\n",
    "    auto_class_weights=\"Balanced\",\n",
    "    random_seed=42,\n",
    "    text_processing={\n",
    "        \"feature_processing\": {\n",
    "            \"default\": [\n",
    "                \"BoW:top_tokens_count=8000\",\n",
    "                \"NaiveBayes\",\n",
    "                \"BM25\",\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    verbose=50,\n",
    ")\n",
    "\n",
    "sector_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7. ACCURACY CHECKS\n",
    "# ============================================================\n",
    "\n",
    "y_val_pred = sector_model.predict(val_pool).astype(int).ravel()\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "\n",
    "print(\"=== SECTOR MODEL METRICS (text + extra text + numeric) ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Macro F1 :\", macro_f1)\n",
    "print(classification_report(y_val, y_val_pred, target_names=le_sector.classes_))\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    \"sector_true\": le_sector.inverse_transform(y_val),\n",
    "    \"sector_pred\": le_sector.inverse_transform(y_val_pred),\n",
    "})\n",
    "val_df[\"correct\"] = (val_df[\"sector_true\"] == val_df[\"sector_pred\"]).astype(int)\n",
    "sector_perf = (\n",
    "    val_df.groupby(\"sector_true\")[\"correct\"]\n",
    "    .agg([\"mean\", \"count\"])\n",
    "    .rename(columns={\"mean\": \"accuracy\", \"count\": \"support\"})\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"\\nPer‑sector accuracy:\")\n",
    "print(sector_perf)\n",
    "\n",
    "sector_perf.to_csv(\"sector_validation_metrics.csv\", index=False)\n",
    "\n",
    "# ============================================================\n",
    "# 8. SAVE ARTIFACTS\n",
    "# ============================================================\n",
    "\n",
    "sector_model.save_model(\"sector_model.cbm\")\n",
    "joblib.dump(le_sector, \"label_encoder_sector.pkl\")\n",
    "joblib.dump(feature_cols_sector, \"sector_feature_cols.joblib\")\n",
    "joblib.dump(text_idx, \"sector_text_idx.joblib\")\n",
    "joblib.dump(cat_idx, \"sector_cat_idx.joblib\")          # still empty\n",
    "joblib.dump(cat_encoders, \"sector_cat_encoders.joblib\")  # still empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153a19fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature frame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11481/11481 [00:44<00:00, 260.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CatBoost for log_views_per_sub...\n",
      "0:\tlearn: 1.5426372\ttest: 1.5553494\tbest: 1.5553494 (0)\ttotal: 8.12ms\tremaining: 3.24s\n",
      "50:\tlearn: 1.3544042\ttest: 1.3765340\tbest: 1.3765340 (50)\ttotal: 374ms\tremaining: 2.56s\n",
      "100:\tlearn: 1.3240459\ttest: 1.3683984\tbest: 1.3683984 (100)\ttotal: 764ms\tremaining: 2.26s\n",
      "150:\tlearn: 1.3024256\ttest: 1.3661057\tbest: 1.3658618 (147)\ttotal: 1.1s\tremaining: 1.82s\n",
      "200:\tlearn: 1.2826009\ttest: 1.3658290\tbest: 1.3647044 (176)\ttotal: 1.43s\tremaining: 1.42s\n",
      "250:\tlearn: 1.2603046\ttest: 1.3662387\tbest: 1.3647044 (176)\ttotal: 1.73s\tremaining: 1.03s\n",
      "300:\tlearn: 1.2408680\ttest: 1.3666738\tbest: 1.3647044 (176)\ttotal: 2.03s\tremaining: 667ms\n",
      "350:\tlearn: 1.2207824\ttest: 1.3668765\tbest: 1.3647044 (176)\ttotal: 2.35s\tremaining: 328ms\n",
      "399:\tlearn: 1.2027819\ttest: 1.3681217\tbest: 1.3647044 (176)\ttotal: 2.68s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.364704434\n",
      "bestIteration = 176\n",
      "\n",
      "Shrink model to first 177 iterations.\n",
      "\n",
      "Training CatBoost for log_likes_per_view...\n",
      "0:\tlearn: 0.0485941\ttest: 0.0339750\tbest: 0.0339750 (0)\ttotal: 5.89ms\tremaining: 2.35s\n",
      "50:\tlearn: 0.0472907\ttest: 0.0334137\tbest: 0.0334137 (50)\ttotal: 319ms\tremaining: 2.19s\n",
      "100:\tlearn: 0.0460369\ttest: 0.0332460\tbest: 0.0332436 (97)\ttotal: 653ms\tremaining: 1.93s\n",
      "150:\tlearn: 0.0446576\ttest: 0.0332799\tbest: 0.0332220 (126)\ttotal: 1.01s\tremaining: 1.66s\n",
      "200:\tlearn: 0.0435215\ttest: 0.0333221\tbest: 0.0332220 (126)\ttotal: 1.34s\tremaining: 1.32s\n",
      "250:\tlearn: 0.0423598\ttest: 0.0333360\tbest: 0.0332220 (126)\ttotal: 1.69s\tremaining: 1s\n",
      "300:\tlearn: 0.0406306\ttest: 0.0334463\tbest: 0.0332220 (126)\ttotal: 2.02s\tremaining: 666ms\n",
      "350:\tlearn: 0.0391334\ttest: 0.0335925\tbest: 0.0332220 (126)\ttotal: 2.34s\tremaining: 326ms\n",
      "399:\tlearn: 0.0381553\ttest: 0.0337072\tbest: 0.0332220 (126)\ttotal: 2.66s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.0332219966\n",
      "bestIteration = 126\n",
      "\n",
      "Shrink model to first 127 iterations.\n",
      "\n",
      "Training CatBoost for engagement_rate...\n",
      "0:\tlearn: 0.1059086\ttest: 0.0678727\tbest: 0.0678727 (0)\ttotal: 5.38ms\tremaining: 2.69s\n",
      "50:\tlearn: 0.0949468\ttest: 0.0674678\tbest: 0.0673887 (41)\ttotal: 312ms\tremaining: 2.75s\n",
      "100:\tlearn: 0.0874735\ttest: 0.0677398\tbest: 0.0673887 (41)\ttotal: 607ms\tremaining: 2.4s\n",
      "150:\tlearn: 0.0819641\ttest: 0.0678063\tbest: 0.0673887 (41)\ttotal: 901ms\tremaining: 2.08s\n",
      "200:\tlearn: 0.0795523\ttest: 0.0679072\tbest: 0.0673887 (41)\ttotal: 1.18s\tremaining: 1.76s\n",
      "250:\tlearn: 0.0768706\ttest: 0.0679770\tbest: 0.0673887 (41)\ttotal: 1.46s\tremaining: 1.45s\n",
      "300:\tlearn: 0.0738538\ttest: 0.0680574\tbest: 0.0673887 (41)\ttotal: 1.75s\tremaining: 1.16s\n",
      "350:\tlearn: 0.0718241\ttest: 0.0681118\tbest: 0.0673887 (41)\ttotal: 2.04s\tremaining: 866ms\n",
      "400:\tlearn: 0.0691642\ttest: 0.0682748\tbest: 0.0673887 (41)\ttotal: 2.33s\tremaining: 576ms\n",
      "450:\tlearn: 0.0673847\ttest: 0.0684837\tbest: 0.0673887 (41)\ttotal: 2.62s\tremaining: 285ms\n",
      "499:\tlearn: 0.0662625\ttest: 0.0685748\tbest: 0.0673887 (41)\ttotal: 2.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06738868363\n",
      "bestIteration = 41\n",
      "\n",
      "Shrink model to first 42 iterations.\n",
      "\n",
      "=== Views per subscriber (ratio target) ===\n",
      "MAE  : 35.7587\n",
      "RMSE : 238.2276\n",
      "R^2  : -0.007\n",
      "\n",
      "=== Likes per view (ratio target) ===\n",
      "MAE  : 0.0231\n",
      "RMSE : 0.0363\n",
      "R^2  : 0.037\n",
      "\n",
      "=== Engagement rate (CatBoost) ===\n",
      "MAE  : 0.0329\n",
      "RMSE : 0.0674\n",
      "R^2  : 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['metric_feature_cols.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_catboost_metrics_richer.py\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Load data\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(\"YouTube_Engineered_Features_Final.csv\").reset_index(drop=True)\n",
    "\n",
    "required_cols = [\n",
    "    \"youtube_title\",\n",
    "    \"youtube_description\",\n",
    "    \"duration_seconds\",\n",
    "    \"youtube_channel_follower_count\",\n",
    "    \"youtube_view_count\",\n",
    "    \"youtube_like_count\",\n",
    "    \"youtube_comment_count\",\n",
    "    \"engagement_rate\",\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=required_cols).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Helper functions for features\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "CALL_TO_ACTION_WORDS = [\n",
    "    \"subscribe\", \"sub\", \"like\", \"comment\", \"share\",\n",
    "    \"watch\", \"click\", \"link\", \"join\", \"follow\",\n",
    "]\n",
    "\n",
    "def extract_sentiment(text: str):\n",
    "    blob = TextBlob(str(text))\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "def readability_features(text: str):\n",
    "    words = text.split()\n",
    "    n_words = len(words)\n",
    "    n_chars = len(text)\n",
    "    avg_word_len = (sum(len(w) for w in words) / n_words) if n_words > 0 else 0.0\n",
    "    n_sentences = max(text.count(\".\") + text.count(\"!\") + text.count(\"?\"), 1)\n",
    "    avg_sentence_len = n_words / n_sentences\n",
    "    # simple Flesch-like proxy (not exact formula, but correlated) [web:177][web:180]\n",
    "    flesch_proxy = 206.835 - 1.015 * avg_sentence_len - 0.84 * avg_word_len\n",
    "    return avg_word_len, avg_sentence_len, flesch_proxy\n",
    "\n",
    "def keyword_features(text: str):\n",
    "    text_l = text.lower()\n",
    "    count = sum(text_l.count(w) for w in CALL_TO_ACTION_WORDS)\n",
    "    present = int(count > 0)\n",
    "    return count, present\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Build feature frame\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"Building feature frame...\")\n",
    "\n",
    "feat_rows = []\n",
    "targets_rows = []\n",
    "\n",
    "for _, row in tqdm(df[required_cols].iterrows(), total=len(df)):\n",
    "    title = str(row[\"youtube_title\"])\n",
    "    desc = str(row[\"youtube_description\"])\n",
    "    full_text = f\"{title} {desc}\"\n",
    "\n",
    "    # sentiment\n",
    "    t_pol, t_sub = extract_sentiment(title)\n",
    "    d_pol, d_sub = extract_sentiment(desc)\n",
    "    c_pol, c_sub = extract_sentiment(full_text)\n",
    "\n",
    "    # readability\n",
    "    avg_word_len, avg_sentence_len, flesch_proxy = readability_features(full_text)\n",
    "\n",
    "    # call-to-action features\n",
    "    cta_count, cta_present = keyword_features(full_text)\n",
    "\n",
    "    duration = float(row[\"duration_seconds\"])\n",
    "    subs = float(row[\"youtube_channel_follower_count\"])\n",
    "    views = float(row[\"youtube_view_count\"])\n",
    "    likes = float(row[\"youtube_like_count\"])\n",
    "    comments = float(row[\"youtube_comment_count\"])\n",
    "    eng_rate = float(row[\"engagement_rate\"])\n",
    "\n",
    "    # derived non-leaky ratios\n",
    "    views_per_sub = views / max(subs, 1.0)\n",
    "    likes_per_view = likes / max(views, 1.0)\n",
    "\n",
    "    feat_rows.append({\n",
    "        \"duration_seconds\": duration,\n",
    "        \"subs\": subs,\n",
    "        \"title_length_chars\": len(title),\n",
    "        \"description_length_chars\": len(desc),\n",
    "        \"title_word_count\": len(title.split()),\n",
    "        \"description_word_count\": len(desc.split()),\n",
    "        \"title_sentiment\": t_pol,\n",
    "        \"title_subjectivity\": t_sub,\n",
    "        \"description_sentiment\": d_pol,\n",
    "        \"description_subjectivity\": d_sub,\n",
    "        \"combined_sentiment\": c_pol,\n",
    "        \"combined_subjectivity\": c_sub,\n",
    "        \"avg_word_length\": avg_word_len,\n",
    "        \"avg_sentence_length\": avg_sentence_len,\n",
    "        \"flesch_proxy\": flesch_proxy,\n",
    "        \"cta_word_count\": cta_count,\n",
    "        \"cta_present\": cta_present,\n",
    "    })\n",
    "\n",
    "    targets_rows.append({\n",
    "        \"log_views_per_sub\": np.log1p(views_per_sub),\n",
    "        \"log_likes_per_view\": np.log1p(likes_per_view),\n",
    "        \"engagement_rate\": eng_rate,\n",
    "    })\n",
    "\n",
    "X = pd.DataFrame(feat_rows)\n",
    "T = pd.DataFrame(targets_rows)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. Train/validation split\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "X_train, X_val, T_train, T_val = train_test_split(\n",
    "    X, T, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_pool = Pool(X_train, label=T_train[\"log_views_per_sub\"])\n",
    "val_pool = Pool(X_val, label=T_val[\"log_views_per_sub\"])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5. Define and train CatBoost models\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def make_regressor():\n",
    "    return CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        iterations=400,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        random_seed=42,\n",
    "        verbose=50,\n",
    "    )\n",
    "\n",
    "print(\"\\nTraining CatBoost for log_views_per_sub...\")\n",
    "model_views = make_regressor()\n",
    "model_views.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "print(\"\\nTraining CatBoost for log_likes_per_view...\")\n",
    "train_pool_l = Pool(X_train, label=T_train[\"log_likes_per_view\"])\n",
    "val_pool_l = Pool(X_val, label=T_val[\"log_likes_per_view\"])\n",
    "model_likes = make_regressor()\n",
    "model_likes.fit(train_pool_l, eval_set=val_pool_l, use_best_model=True)\n",
    "\n",
    "print(\"\\nTraining CatBoost for engagement_rate...\")\n",
    "train_pool_e = Pool(X_train, label=T_train[\"engagement_rate\"])\n",
    "val_pool_e = Pool(X_val, label=T_val[\"engagement_rate\"])\n",
    "model_eng = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    ")\n",
    "model_eng.fit(train_pool_e, eval_set=val_pool_e, use_best_model=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 6. Accuracy checks\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def print_reg_metrics_ratio(name, y_true_log, y_pred_log, scale_desc):\n",
    "    y_true = np.expm1(y_true_log)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} ({scale_desc}) ===\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"R^2  : {r2:.3f}\")\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# views per sub\n",
    "y_v_true = T_val[\"log_views_per_sub\"].values\n",
    "y_v_pred = model_views.predict(X_val)\n",
    "print_reg_metrics_ratio(\n",
    "    \"Views per subscriber\",\n",
    "    y_v_true,\n",
    "    y_v_pred,\n",
    "    \"ratio target\"\n",
    ")\n",
    "\n",
    "# likes per view\n",
    "y_l_true = T_val[\"log_likes_per_view\"].values\n",
    "y_l_pred = model_likes.predict(X_val)\n",
    "print_reg_metrics_ratio(\n",
    "    \"Likes per view\",\n",
    "    y_l_true,\n",
    "    y_l_pred,\n",
    "    \"ratio target\"\n",
    ")\n",
    "\n",
    "# engagement rate (already [0,1])\n",
    "y_e_true = T_val[\"engagement_rate\"].values\n",
    "y_e_pred = model_eng.predict(X_val)\n",
    "\n",
    "mae_e = mean_absolute_error(y_e_true, y_e_pred)\n",
    "rmse_e = mean_squared_error(y_e_true, y_e_pred, squared=False)\n",
    "r2_e = r2_score(y_e_true, y_e_pred)\n",
    "\n",
    "print(\"\\n=== Engagement rate (CatBoost) ===\")\n",
    "print(f\"MAE  : {mae_e:.4f}\")\n",
    "print(f\"RMSE : {rmse_e:.4f}\")\n",
    "print(f\"R^2  : {r2_e:.3f}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 7. Save models and feature list\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "model_views.save_model(\"cb_log_views_per_sub.cbm\")\n",
    "model_likes.save_model(\"cb_log_likes_per_view.cbm\")\n",
    "model_eng.save_model(\"cb_engagement_rate.cbm\")\n",
    "joblib.dump(list(X.columns), \"metric_feature_cols.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61bbc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature and target frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11481/11481 [00:36<00:00, 318.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Views per subscriber tier model...\n",
      "0:\tlearn: 0.4313976\ttest: 0.4414337\tbest: 0.4414337 (0)\ttotal: 11.2ms\tremaining: 4.47s\n",
      "50:\tlearn: 0.4858310\ttest: 0.4643804\tbest: 0.4661543 (39)\ttotal: 817ms\tremaining: 5.59s\n",
      "100:\tlearn: 0.5144146\ttest: 0.4766655\tbest: 0.4796358 (94)\ttotal: 1.67s\tremaining: 4.95s\n",
      "150:\tlearn: 0.5365792\ttest: 0.4796975\tbest: 0.4824427 (146)\ttotal: 2.6s\tremaining: 4.28s\n",
      "200:\tlearn: 0.5517939\ttest: 0.4806667\tbest: 0.4852494 (193)\ttotal: 3.37s\tremaining: 3.33s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.485249434\n",
      "bestIteration = 193\n",
      "\n",
      "Shrink model to first 194 iterations.\n",
      "\n",
      "=== Views per subscriber TIER MODEL ===\n",
      "Accuracy : 0.501523726599913\n",
      "Macro F1 : 0.48613172789486764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HIGH      0.510     0.684     0.584       781\n",
      "         LOW      0.510     0.530     0.520       758\n",
      "         MID      0.468     0.285     0.354       758\n",
      "\n",
      "    accuracy                          0.502      2297\n",
      "   macro avg      0.496     0.500     0.486      2297\n",
      "weighted avg      0.496     0.502     0.487      2297\n",
      "\n",
      "\n",
      "Training Likes per view tier model...\n",
      "0:\tlearn: 0.4406921\ttest: 0.4300653\tbest: 0.4300653 (0)\ttotal: 12.5ms\tremaining: 5s\n",
      "50:\tlearn: 0.5019192\ttest: 0.4628827\tbest: 0.4704234 (35)\ttotal: 745ms\tremaining: 5.1s\n",
      "100:\tlearn: 0.5272475\ttest: 0.4707858\tbest: 0.4746316 (94)\ttotal: 1.51s\tremaining: 4.46s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4746315589\n",
      "bestIteration = 94\n",
      "\n",
      "Shrink model to first 95 iterations.\n",
      "\n",
      "=== Likes per view TIER MODEL ===\n",
      "Accuracy : 0.49063996517196345\n",
      "Macro F1 : 0.4748559911944364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HIGH      0.523     0.535     0.529       781\n",
      "         LOW      0.503     0.674     0.576       758\n",
      "         MID      0.411     0.261     0.319       758\n",
      "\n",
      "    accuracy                          0.491      2297\n",
      "   macro avg      0.479     0.490     0.475      2297\n",
      "weighted avg      0.479     0.491     0.475      2297\n",
      "\n",
      "\n",
      "Training Engagement rate tier model...\n",
      "0:\tlearn: 0.4336916\ttest: 0.4193498\tbest: 0.4193498 (0)\ttotal: 11.9ms\tremaining: 4.76s\n",
      "50:\tlearn: 0.5042152\ttest: 0.4701537\tbest: 0.4714722 (47)\ttotal: 827ms\tremaining: 5.66s\n",
      "100:\tlearn: 0.5274832\ttest: 0.4732662\tbest: 0.4759369 (98)\ttotal: 1.63s\tremaining: 4.81s\n",
      "150:\tlearn: 0.5474941\ttest: 0.4780250\tbest: 0.4802503 (127)\ttotal: 2.44s\tremaining: 4.01s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4802503296\n",
      "bestIteration = 127\n",
      "\n",
      "Shrink model to first 128 iterations.\n",
      "\n",
      "=== Engagement rate TIER MODEL ===\n",
      "Accuracy : 0.4936874183717893\n",
      "Macro F1 : 0.48064427781986013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HIGH      0.527     0.577     0.551       781\n",
      "         LOW      0.504     0.624     0.558       758\n",
      "         MID      0.417     0.277     0.333       758\n",
      "\n",
      "    accuracy                          0.494      2297\n",
      "   macro avg      0.483     0.493     0.481      2297\n",
      "weighted avg      0.483     0.494     0.481      2297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tier_classes_eng_rate.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_best_performance_tier_models.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import joblib\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Load data\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(\"YouTube_Engineered_Features_Final.csv\").reset_index(drop=True)\n",
    "\n",
    "required_cols = [\n",
    "    \"youtube_title\",\n",
    "    \"youtube_description\",\n",
    "    \"duration_seconds\",\n",
    "    \"youtube_channel_follower_count\",\n",
    "    \"youtube_view_count\",\n",
    "    \"youtube_like_count\",\n",
    "    \"youtube_comment_count\",\n",
    "    \"engagement_rate\",\n",
    "]\n",
    "df = df.dropna(subset=required_cols).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Feature helpers\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "CALL_TO_ACTION_WORDS = [\n",
    "    \"subscribe\", \"sub\", \"like\", \"comment\", \"share\",\n",
    "    \"watch\", \"click\", \"link\", \"join\", \"follow\",\n",
    "]\n",
    "\n",
    "def extract_sentiment(text: str):\n",
    "    blob = TextBlob(str(text))\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "def readability_features(text: str):\n",
    "    words = text.split()\n",
    "    n_words = len(words)\n",
    "    avg_word_len = (sum(len(w) for w in words) / n_words) if n_words > 0 else 0.0\n",
    "    n_sentences = max(text.count(\".\") + text.count(\"!\") + text.count(\"?\"), 1)\n",
    "    avg_sentence_len = n_words / n_sentences\n",
    "    flesch_proxy = 206.835 - 1.015 * avg_sentence_len - 0.84 * avg_word_len\n",
    "    return avg_word_len, avg_sentence_len, flesch_proxy\n",
    "\n",
    "def keyword_features(text: str):\n",
    "    text_l = text.lower()\n",
    "    count = sum(text_l.count(w) for w in CALL_TO_ACTION_WORDS)\n",
    "    present = int(count > 0)\n",
    "    return count, present\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Build features and targets\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"Building feature and target frames...\")\n",
    "\n",
    "feat_rows = []\n",
    "target_rows = []\n",
    "\n",
    "for _, row in tqdm(df[required_cols].iterrows(), total=len(df)):\n",
    "    title = str(row[\"youtube_title\"])\n",
    "    desc = str(row[\"youtube_description\"])\n",
    "    full_text = f\"{title} {desc}\"\n",
    "\n",
    "    duration = float(row[\"duration_seconds\"])\n",
    "    subs = float(row[\"youtube_channel_follower_count\"])\n",
    "    views = float(row[\"youtube_view_count\"])\n",
    "    likes = float(row[\"youtube_like_count\"])\n",
    "    comments = float(row[\"youtube_comment_count\"])\n",
    "    eng_rate = float(row[\"engagement_rate\"])\n",
    "\n",
    "    # derived ratios (no leakage of exact train labels at inference, since\n",
    "    # only title/desc/duration/subs will be available there)\n",
    "    views_per_sub = views / max(subs, 1.0)\n",
    "    likes_per_view = likes / max(views, 1.0)\n",
    "\n",
    "    # sentiment\n",
    "    t_pol, t_sub = extract_sentiment(title)\n",
    "    d_pol, d_sub = extract_sentiment(desc)\n",
    "    c_pol, c_sub = extract_sentiment(full_text)\n",
    "\n",
    "    # readability\n",
    "    avg_word_len, avg_sentence_len, flesch_proxy = readability_features(full_text)\n",
    "\n",
    "    # call-to-action\n",
    "    cta_count, cta_present = keyword_features(full_text)\n",
    "\n",
    "    feat_rows.append({\n",
    "        \"duration_seconds\": duration,\n",
    "        \"subs\": subs,\n",
    "        \"title_length_chars\": len(title),\n",
    "        \"description_length_chars\": len(desc),\n",
    "        \"title_word_count\": len(title.split()),\n",
    "        \"description_word_count\": len(desc.split()),\n",
    "        \"title_sentiment\": t_pol,\n",
    "        \"title_subjectivity\": t_sub,\n",
    "        \"description_sentiment\": d_pol,\n",
    "        \"description_subjectivity\": d_sub,\n",
    "        \"combined_sentiment\": c_pol,\n",
    "        \"combined_subjectivity\": c_sub,\n",
    "        \"avg_word_length\": avg_word_len,\n",
    "        \"avg_sentence_length\": avg_sentence_len,\n",
    "        \"flesch_proxy\": flesch_proxy,\n",
    "        \"cta_word_count\": cta_count,\n",
    "        \"cta_present\": cta_present,\n",
    "    })\n",
    "\n",
    "    target_rows.append({\n",
    "        \"views_per_sub\": views_per_sub,\n",
    "        \"likes_per_view\": likes_per_view,\n",
    "        \"engagement_rate\": eng_rate,\n",
    "    })\n",
    "\n",
    "X = pd.DataFrame(feat_rows)\n",
    "T = pd.DataFrame(target_rows)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. Create tier labels (Low / Mid / High) using quantiles\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def make_tiers(series, low_q=0.33, high_q=0.66):\n",
    "    lo = series.quantile(low_q)\n",
    "    hi = series.quantile(high_q)\n",
    "    def _tier(x):\n",
    "        if x <= lo:\n",
    "            return \"LOW\"\n",
    "        elif x >= hi:\n",
    "            return \"HIGH\"\n",
    "        else:\n",
    "            return \"MID\"\n",
    "    return series.apply(_tier)\n",
    "\n",
    "T[\"tier_views_per_sub\"] = make_tiers(T[\"views_per_sub\"])\n",
    "T[\"tier_likes_per_view\"] = make_tiers(T[\"likes_per_view\"])\n",
    "T[\"tier_eng_rate\"] = make_tiers(T[\"engagement_rate\"])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5. Generic training function (fixed)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def train_tier_model(X, y, label_name):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    train_pool = Pool(X_train, label=y_train)\n",
    "    val_pool = Pool(X_val, label=y_val)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"MultiClass\",\n",
    "        eval_metric=\"TotalF1:average=Macro\",\n",
    "        iterations=400,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        random_seed=42,\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        verbose=50,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining {label_name} tier model...\")\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True, early_stopping_rounds=50)\n",
    "\n",
    "    # CatBoost returns labels in the same format used for y (strings)\n",
    "    y_pred_str = model.predict(val_pool).reshape(-1)\n",
    "    y_val_str = y_val.values\n",
    "\n",
    "    acc = accuracy_score(y_val_str, y_pred_str)\n",
    "    macro_f1 = f1_score(y_val_str, y_pred_str, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n=== {label_name} TIER MODEL ===\")\n",
    "    print(\"Accuracy :\", acc)\n",
    "    print(\"Macro F1 :\", macro_f1)\n",
    "    print(classification_report(y_val_str, y_pred_str, digits=3))\n",
    "\n",
    "    classes = np.unique(y)\n",
    "    return model, classes\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 6. Train three tier models\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "y_vps = T[\"tier_views_per_sub\"]\n",
    "y_lpv = T[\"tier_likes_per_view\"]\n",
    "y_er  = T[\"tier_eng_rate\"]\n",
    "\n",
    "model_vps, classes_vps = train_tier_model(X, y_vps, \"Views per subscriber\")\n",
    "model_lpv, classes_lpv = train_tier_model(X, y_lpv, \"Likes per view\")\n",
    "model_er,  classes_er  = train_tier_model(X, y_er,  \"Engagement rate\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 7. Save artifacts\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "model_vps.save_model(\"cb_tier_views_per_sub.cbm\")\n",
    "model_lpv.save_model(\"cb_tier_likes_per_view.cbm\")\n",
    "model_er.save_model(\"cb_tier_eng_rate.cbm\")\n",
    "\n",
    "joblib.dump(list(X.columns), \"tier_metric_feature_cols.pkl\")\n",
    "joblib.dump(classes_vps, \"tier_classes_views_per_sub.pkl\")\n",
    "joblib.dump(classes_lpv, \"tier_classes_likes_per_view.pkl\")\n",
    "joblib.dump(classes_er,  \"tier_classes_eng_rate.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75c1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
